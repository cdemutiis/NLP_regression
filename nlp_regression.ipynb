{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "Latex Macros\n",
    "-->\n",
    "$$\n",
    "\\newcommand{\\bar}{\\,|\\,}\n",
    "\\newcommand{\\Xs}{\\mathcal{X}}\n",
    "\\newcommand{\\Ys}{\\mathcal{Y}}\n",
    "\\newcommand{\\y}{\\mathbf{y}}\n",
    "\\newcommand{\\weights}{\\mathbf{w}}\n",
    "\\newcommand{\\balpha}{\\boldsymbol{\\alpha}}\n",
    "\\newcommand{\\bbeta}{\\boldsymbol{\\beta}}\n",
    "\\newcommand{\\aligns}{\\mathbf{a}}\n",
    "\\newcommand{\\align}{a}\n",
    "\\newcommand{\\source}{\\mathbf{s}}\n",
    "\\newcommand{\\target}{\\mathbf{t}}\n",
    "\\newcommand{\\ssource}{s}\n",
    "\\newcommand{\\starget}{t}\n",
    "\\newcommand{\\repr}{\\mathbf{f}}\n",
    "\\newcommand{\\repry}{\\mathbf{g}}\n",
    "\\newcommand{\\x}{\\mathbf{x}}\n",
    "\\newcommand{\\prob}{p}\n",
    "\\newcommand{\\vocab}{V}\n",
    "\\newcommand{\\params}{\\boldsymbol{\\theta}}\n",
    "\\newcommand{\\param}{\\theta}\n",
    "\\DeclareMathOperator{\\perplexity}{PP}\n",
    "\\DeclareMathOperator{\\argmax}{argmax}\n",
    "\\DeclareMathOperator{\\argmin}{argmin}\n",
    "\\newcommand{\\train}{\\mathcal{D}}\n",
    "\\newcommand{\\counts}[2]{\\#_{#1}(#2) }\n",
    "\\newcommand{\\length}[1]{\\text{length}(#1) }\n",
    "\\newcommand{\\indi}{\\mathbb{I}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "## Introduction\n",
    "In this assignment you will build the first stage of a biomedical event extractor. Biomedical events are state changes of biomolecules. For example, if you have a protein and you add a phosphate (PO4) group to it, this is referred to as a phosphorylation event. Many papers in the biomedical literature mention such events. The grand goal of biomedical event extraction is to teach machines how to read this literature and produce structured representations of biomedical events that biomedical researchers can query effectively. This task has received considerable attention in the NLP literature, and is the topic of a biennial [shared task](http://2011.bionlp-st.org/). We will use the data from this task as starting point for this assignment.   \n",
    "\n",
    "To illustrate biomedical event extraction, let us consider an example. From the sentence \n",
    "\n",
    "> **phosphorylation** of TRAF2 **inhibits** **binding** to the CD40 domain\n",
    "\n",
    "we could extract the structure \n",
    "\n",
    "> Negative_Regulation(Phosphorylation(TRAF2), Binding(TRAF2, CD40)\n",
    "\n",
    "and store it in a database. Someone can then query this database, for example, to figure out all ways to prevent binding of TRAF2 to CD40.\n",
    "\n",
    "The task is often divided into two steps. First you need to find **trigger** words in the sentence that correspond to biomedical events, and determine their event type *label*. For example, in the above sentence \"phosphorylation\" is a trigger word for an event of type \"Phosphorylation\", \"inhibits\" a trigger word for a \"Negative Regulation\" event, and \"binding\" a trigger for a \"Binding\" event. Notice that sometimes the type labels are obvious, but often they are not. Also note that the label of a word could be \"None\". For example, the word \"of\" in the above sentence has the label \"None\".  \n",
    "\n",
    "The second step requires the extractor to produce **argument relations** between event triggers and protein mentions or other event triggers. For example, in the above case the argument of \"phosphorylation\" is \"TRAF2\", and one argument of \"inhibits\" is \"phosphorylation of TRAF2\" whereas the other is \"binding to the CD40 domain\". In this assignment you **do not have to do this**. We will focus on the event trigger detection problem exclusively. \n",
    "\n",
    "## Goal\n",
    "Your goal is to develop an event trigger labeler. This extractor is given a sentence and a candidate token. Both constitute the input $\\x$. One such input could be: \n",
    "\n",
    "> $\\x$: phosphorylation of TRAF2 **inhibits** binding to the CD40 domain\n",
    "\n",
    "The goal is to predict the label $y$ of the candidate event trigger. In the above case the label would be $y=\\text{Negative_Regulation}$. \n",
    "\n",
    "Some candidates may not refer to event triggers at all. For example:\n",
    "\n",
    "> $\\x$: phosphorylation **of** TRAF2 inhibits binding to the CD40 domain\n",
    "\n",
    "In such cases the label is $y=\\text{None}$.\n",
    "\n",
    "## Resources\n",
    "To develop your model you have access to:\n",
    "\n",
    "* The data in `data/bionlp/train`. This data can be split into training and dev set (as done below), or used for cross-validation.\n",
    "* Helper code stored in the python module [bio.py](/edit/statnlpbook/bio.py).\n",
    "* Libraries on the [docker image](https://github.com/uclmr/stat-nlp-book/blob/python/Dockerfile) which contains everything in [this image](https://github.com/jupyter/docker-stacks/tree/master/scipy-notebook), including scikit-learn and tensorflow. \n",
    "\n",
    "As we have to run the notebooks of all students, and because writing efficient code is important, **your notebook should run in 5 minutes at most**, on your machine. Further comments:\n",
    "\n",
    "* We have tested a possible solution on the Azure VMs and it ran in about 30s, so it is possible to train a reasonable model on the data in reasonable time. If you find training times too long for your development cycle you can reduce the training set size. Once you have found a good solution you can increase the size again. Caveat: model parameters tuned on a smaller dataset may not be optimal for a larger training set.\n",
    "\n",
    "* Try to run your parameter optimisation offline, such that in your answer notebook the best parameters are already set and don't need to be searched. Include your optimisation code in the notebook, but don't call it at each notebook run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hint\n",
    "While you do not need to predict the arguments of an event, it is important to understand how trigger labels relate to the syntactic and semantic arguments of the trigger word. Features that can capture this relation might help you in improving the result. Do inspect the data and try to get an understanding of it. That said, you don't have to be a biomedical expert to do well in this task. A few of the best results on the task were achieved by NLP researchers without any biomedical experience. They would, however, still inspect the data carefully.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Instructions\n",
    "It is important that this file is placed in the **correct directory**. It will not run otherwise. The correct directory is\n",
    "\n",
    "    DIRECTORY_OF_YOUR_BOOK/assignments/2016/assignment2/problem/\n",
    "    \n",
    "where `DIRECTORY_OF_YOUR_BOOK` is a placeholder for the directory you downloaded the book to. After you placed it there, **rename the file** to your UCL ID (of the form `ucxxxxx`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Instructions\n",
    "This notebook will be used by you to provide your solution, and by us to both assess your solution and enter your marks. It contains three types of sections:\n",
    "\n",
    "1. **Setup** Sections: these sections set up code and resources for assessment. **Do not edit, move nor copy these cells**.\n",
    "2. **Assessment** Sections: these sections are used for both evaluating the output of your code, and for markers to enter their marks. **Do not edit, move, nor copy these cells**.\n",
    "3. **Task** Sections: these sections require your solutions. They may contain stub code, and you are expected to edit this code. For free text answers simply edit the markdown field.  \n",
    "\n",
    "**If you edit, move or copy any of the setup, assessments and mark cells, you will be penalised with -10 points**.\n",
    "\n",
    "Note that you are free to **create additional notebook cells** within a task section. \n",
    "\n",
    "Please **do not share** this assignment publicly, by uploading it online, emailing it to friends etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Instructions\n",
    "\n",
    "To submit your solution:\n",
    "\n",
    "* Make sure that your solution is fully contained in this notebook. \n",
    "* Make sure that your solution runs linearly from start to end (no execution hops). We will run your notebook in that order.\n",
    "* **If running your notebook produces a trivially fixable error that we spot, we will correct it and penalise you with -10 points. Otherwise you will get 0 points for that solution.**\n",
    "* **Rename this notebook to your UCL ID** (of the form \"ucxxxxx\"), if you have not already done so. ** Failure to do so will result in -1 point.**\n",
    "* Download the notebook in Jupyter via *File -> Download as -> Notebook (.ipynb)*.\n",
    "* Upload the notebook to the Moodle submission site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 1</font>: Load Libraries\n",
    "This cell loads libraries important for evaluation and assessment of your model. **Do not change, move or copy it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "#! SETUP 1 - DO NOT CHANGE, MOVE NOR COPY\n",
    "import sys, os\n",
    "_snlp_book_dir = \"../../../../\"\n",
    "sys.path.append(_snlp_book_dir) \n",
    "import math\n",
    "from collections import defaultdict\n",
    "import statnlpbook.bio as bio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 2</font>: Load Training Data\n",
    "\n",
    "This cell loads the training data. **Do not edit this setup section, nor copy it**. Instead refer to the variables in your own code, and slice and dice them as you see fit (but do not change their values). For example, no one will stop you from introducing, in the corresponding task section, `my_event_train` and `my_event_dev` variables that split the data into different folds.   \n",
    "\n",
    "Notice that the data is loaded from `json` files like [this one](/edit/data/bionlp/train/PMC-1310901-00-TIAB.json). Generally, you do not need to understand this format, as we provide loading functions that produce more convenient data structures shown below. But do feel free to investigate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#! SETUP 2 - DO NOT CHANGE, MOVE NOR COPY\n",
    "train_path = _snlp_book_dir + \"data/bionlp/train\"\n",
    "event_corpus = bio.load_assignment2_training_data(train_path)\n",
    "event_train = event_corpus[:len(event_corpus)//4 * 3]\n",
    "event_dev = event_corpus[len(event_corpus)//4 * 3:]\n",
    "assert(len(event_train)==53988)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structures\n",
    "The data comes in the form of pairs consisting of `EventCandidate` objects and their trigger labels. The `EventCandidate` class can be found in [bio.py](/edit/statnlpbook/bio.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<statnlpbook.bio.EventCandidate at 0x7f5143c0e5c0>, 'Negative_regulation')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_candidate, label = event_corpus[0]\n",
    "(event_candidate, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Event candidate objects specify the classification problem. They consist of a sentence `sent` and the position `trigger_index` of the trigger candidate word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Down-regulation of interferon regulatory factor 4 gene expression in leukemic cells due to hypermethylation of CpG motifs in the promoter region Although the bcr -abl translocation has been shown to be the causative genetic aberration in chronic myeloid leukemia ( CML ) , there is mounting evidence that the deregulation of other genes , such as the transcription factor interferon regulatory factor 4 ( IRF-4 ) , is also implicated in the pathogenesis of CML ."
      ],
      "text/plain": [
       "<statnlpbook.bio.Sentence at 0x7f5143c0e588>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_candidate.sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_candidate.trigger_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Event candidates also have a set of candidate arguments. These point to token spans (index of first token, inclusive, index of last token, exclusive) in the sentence that may or may not be *arguments* of the event. In the full event extraction task one needs to predict which of these candidates are true arguments of the events. However, here we will ignore this task, and give you only the information what candidates exist, not what their labels are. Note that this information can still be **very important** to understand what type of event the candidate corresponds to, if any. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 6), (23, 24), (24, 25), (59, 63)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_candidate.argument_candidate_spans[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compactly visualise the complete candidate using `bio.render_event`, as shown below. Here the green span corresponds to the token at the trigger index. The spans in red brackets correspond to the argument candidates. The blue spans are protein mentions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font color='green'>Down-regulation</font> <font color='red'>[</font>of<font color='red'>]</font> <font color='red'>[</font><font color='blue'>[interferon regulatory factor 4]</font><font color='red'>]</font> gene <font color='red'>[</font>expression<font color='red'>]</font> in leukemic cells <font color='red'>[</font>due<font color='red'>]</font> <font color='red'>[</font>to<font color='red'>]</font> hypermethylation <font color='red'>[</font>of<font color='red'>]</font> CpG motifs in the <font color='red'>[</font>promoter<font color='red'>]</font> region Although the <font color='red'>[</font><font color='blue'>[bcr]</font><font color='red'>]</font> <font color='red'>[</font><font color='blue'>[-abl]</font><font color='red'>]</font> <font color='red'>[</font>translocation<font color='red'>]</font> has been shown <font color='red'>[</font>to<font color='red'>]</font> be the causative genetic <font color='red'>[</font>aberration<font color='red'>]</font> in chronic myeloid leukemia ( CML ) , there is mounting evidence <font color='red'>[</font>that<font color='red'>]</font> the <font color='red'>[</font>deregulation<font color='red'>]</font> <font color='red'>[</font>of<font color='red'>]</font> other genes , such as the <font color='red'>[</font>transcription<font color='red'>]</font> <font color='red'>[</font>factor<font color='red'>]</font> <font color='red'>[</font><font color='blue'>[interferon regulatory factor 4]</font><font color='red'>]</font> ( <font color='red'>[</font><font color='blue'>[IRF-4]</font><font color='red'>]</font> ) , is also <font color='red'>[</font>implicated<font color='red'>]</font> in the pathogenesis <font color='red'>[</font>of<font color='red'>]</font> CML ."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio.render_event(event_candidate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentences\n",
    "The sentence object of an event candidate provides additional information about the sentence, such as what spans are proteins, what Part-of-Speech labels the tokens have, and a dependency parse of the sentence. First, the `tokens` field of a sentence provides useful features of tokens: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'begin': 0,\n",
       " 'end': 15,\n",
       " 'index': 0,\n",
       " 'pos': 'NN',\n",
       " 'stem': 'Down-regul',\n",
       " 'word': 'Down-regulation'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_candidate.sent.tokens[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dependencies` field stores lexical dependencies between words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'head': 44, 'label': 'nsubj', 'mod': 0},\n",
       " {'head': 4, 'label': 'nn', 'mod': 2}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_candidate.sent.dependencies[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can render the dependency graph of a sentence like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div id='displacy3' style=\"overflow: scroll; width: 5000px;\"></div>\n",
       "    <script>\n",
       "    $(function() {\n",
       "    requirejs.config({\n",
       "        paths: {\n",
       "            'displaCy': ['/files/node_modules/displacy/displacy'],\n",
       "                                                  // strip .js ^, require adds it back\n",
       "        },\n",
       "    });\n",
       "    require(['displaCy'], function() {\n",
       "        console.log(\"Loaded :)\");\n",
       "        const displacy = new displaCy('http://localhost:8000', {\n",
       "            container: '#displacy3',\n",
       "            format: 'spacy',\n",
       "            distance: 150,\n",
       "            offsetX: 0,\n",
       "            wordSpacing: 20,\n",
       "            arrowSpacing: 3,\n",
       "\n",
       "        });\n",
       "        const parse = {\n",
       "            arcs: [{\"end\": 44, \"label\": \"nsubj\", \"start\": 0, \"dir\": \"left\"}, {\"end\": 4, \"label\": \"nn\", \"start\": 2, \"dir\": \"left\"}, {\"end\": 4, \"label\": \"amod\", \"start\": 3, \"dir\": \"left\"}, {\"end\": 7, \"label\": \"nn\", \"start\": 4, \"dir\": \"left\"}, {\"end\": 5, \"label\": \"num\", \"start\": 4, \"dir\": \"right\"}, {\"end\": 7, \"label\": \"nn\", \"start\": 6, \"dir\": \"left\"}, {\"end\": 7, \"label\": \"prep_of\", \"start\": 0, \"dir\": \"right\"}, {\"end\": 10, \"label\": \"amod\", \"start\": 9, \"dir\": \"left\"}, {\"end\": 10, \"label\": \"prep_in\", \"start\": 7, \"dir\": \"right\"}, {\"end\": 13, \"label\": \"prep_due_to\", \"start\": 7, \"dir\": \"right\"}, {\"end\": 16, \"label\": \"nn\", \"start\": 15, \"dir\": \"left\"}, {\"end\": 16, \"label\": \"prep_of\", \"start\": 13, \"dir\": \"right\"}, {\"end\": 20, \"label\": \"det\", \"start\": 18, \"dir\": \"left\"}, {\"end\": 20, \"label\": \"nn\", \"start\": 19, \"dir\": \"left\"}, {\"end\": 20, \"label\": \"prep_in\", \"start\": 0, \"dir\": \"right\"}, {\"end\": 28, \"label\": \"mark\", \"start\": 21, \"dir\": \"left\"}, {\"end\": 25, \"label\": \"det\", \"start\": 22, \"dir\": \"left\"}, {\"end\": 25, \"label\": \"nn\", \"start\": 23, \"dir\": \"left\"}, {\"end\": 25, \"label\": \"nn\", \"start\": 24, \"dir\": \"left\"}, {\"end\": 28, \"label\": \"nsubjpass\", \"start\": 25, \"dir\": \"left\"}, {\"end\": 34, \"label\": \"xsubj\", \"start\": 25, \"dir\": \"left\"}, {\"end\": 28, \"label\": \"aux\", \"start\": 26, \"dir\": \"left\"}, {\"end\": 28, \"label\": \"auxpass\", \"start\": 27, \"dir\": \"left\"}, {\"end\": 44, \"label\": \"advcl\", \"start\": 28, \"dir\": \"left\"}, {\"end\": 34, \"label\": \"aux\", \"start\": 29, \"dir\": \"left\"}, {\"end\": 34, \"label\": \"cop\", \"start\": 30, \"dir\": \"left\"}, {\"end\": 34, \"label\": \"det\", \"start\": 31, \"dir\": \"left\"}, {\"end\": 34, \"label\": \"amod\", \"start\": 32, \"dir\": \"left\"}, {\"end\": 34, \"label\": \"amod\", \"start\": 33, \"dir\": \"left\"}, {\"end\": 34, \"label\": \"xcomp\", \"start\": 28, \"dir\": \"right\"}, {\"end\": 38, \"label\": \"amod\", \"start\": 36, \"dir\": \"left\"}, {\"end\": 38, \"label\": \"amod\", \"start\": 37, \"dir\": \"left\"}, {\"end\": 38, \"label\": \"prep_in\", \"start\": 34, \"dir\": \"right\"}, {\"end\": 40, \"label\": \"abbrev\", \"start\": 38, \"dir\": \"right\"}, {\"end\": 44, \"label\": \"expl\", \"start\": 43, \"dir\": \"left\"}, {\"end\": 46, \"label\": \"amod\", \"start\": 45, \"dir\": \"left\"}, {\"end\": 46, \"label\": \"nsubj\", \"start\": 44, \"dir\": \"right\"}, {\"end\": 69, \"label\": \"complm\", \"start\": 47, \"dir\": \"left\"}, {\"end\": 49, \"label\": \"det\", \"start\": 48, \"dir\": \"left\"}, {\"end\": 69, \"label\": \"nsubjpass\", \"start\": 49, \"dir\": \"left\"}, {\"end\": 52, \"label\": \"amod\", \"start\": 51, \"dir\": \"left\"}, {\"end\": 52, \"label\": \"prep_of\", \"start\": 49, \"dir\": \"right\"}, {\"end\": 61, \"label\": \"det\", \"start\": 56, \"dir\": \"left\"}, {\"end\": 61, \"label\": \"nn\", \"start\": 57, \"dir\": \"left\"}, {\"end\": 61, \"label\": \"nn\", \"start\": 58, \"dir\": \"left\"}, {\"end\": 61, \"label\": \"nn\", \"start\": 59, \"dir\": \"left\"}, {\"end\": 61, \"label\": \"amod\", \"start\": 60, \"dir\": \"left\"}, {\"end\": 61, \"label\": \"prep_such_as\", \"start\": 52, \"dir\": \"right\"}, {\"end\": 62, \"label\": \"num\", \"start\": 61, \"dir\": \"right\"}, {\"end\": 64, \"label\": \"abbrev\", \"start\": 61, \"dir\": \"right\"}, {\"end\": 69, \"label\": \"auxpass\", \"start\": 67, \"dir\": \"left\"}, {\"end\": 69, \"label\": \"advmod\", \"start\": 68, \"dir\": \"left\"}, {\"end\": 69, \"label\": \"ccomp\", \"start\": 46, \"dir\": \"right\"}, {\"end\": 72, \"label\": \"det\", \"start\": 71, \"dir\": \"left\"}, {\"end\": 72, \"label\": \"prep_in\", \"start\": 69, \"dir\": \"right\"}, {\"end\": 74, \"label\": \"prep_of\", \"start\": 72, \"dir\": \"right\"}],\n",
       "            words: [{\"tag\": \"NN\", \"text\": \"Down-regulation\"}, {\"tag\": \"IN\", \"text\": \"of\"}, {\"tag\": \"NN\", \"text\": \"interferon\"}, {\"tag\": \"JJ\", \"text\": \"regulatory\"}, {\"tag\": \"NN\", \"text\": \"factor\"}, {\"tag\": \"CD\", \"text\": \"4\"}, {\"tag\": \"NN\", \"text\": \"gene\"}, {\"tag\": \"NN\", \"text\": \"expression\"}, {\"tag\": \"IN\", \"text\": \"in\"}, {\"tag\": \"JJ\", \"text\": \"leukemic\"}, {\"tag\": \"NNS\", \"text\": \"cells\"}, {\"tag\": \"IN\", \"text\": \"due\"}, {\"tag\": \"TO\", \"text\": \"to\"}, {\"tag\": \"NN\", \"text\": \"hypermethylation\"}, {\"tag\": \"IN\", \"text\": \"of\"}, {\"tag\": \"NN\", \"text\": \"CpG\"}, {\"tag\": \"NNS\", \"text\": \"motifs\"}, {\"tag\": \"IN\", \"text\": \"in\"}, {\"tag\": \"DT\", \"text\": \"the\"}, {\"tag\": \"NN\", \"text\": \"promoter\"}, {\"tag\": \"NN\", \"text\": \"region\"}, {\"tag\": \"IN\", \"text\": \"Although\"}, {\"tag\": \"DT\", \"text\": \"the\"}, {\"tag\": \"NN\", \"text\": \"bcr\"}, {\"tag\": \"NN\", \"text\": \"-abl\"}, {\"tag\": \"NN\", \"text\": \"translocation\"}, {\"tag\": \"VBZ\", \"text\": \"has\"}, {\"tag\": \"VBN\", \"text\": \"been\"}, {\"tag\": \"VBN\", \"text\": \"shown\"}, {\"tag\": \"TO\", \"text\": \"to\"}, {\"tag\": \"VB\", \"text\": \"be\"}, {\"tag\": \"DT\", \"text\": \"the\"}, {\"tag\": \"JJ\", \"text\": \"causative\"}, {\"tag\": \"JJ\", \"text\": \"genetic\"}, {\"tag\": \"NN\", \"text\": \"aberration\"}, {\"tag\": \"IN\", \"text\": \"in\"}, {\"tag\": \"JJ\", \"text\": \"chronic\"}, {\"tag\": \"JJ\", \"text\": \"myeloid\"}, {\"tag\": \"NN\", \"text\": \"leukemia\"}, {\"tag\": \"-LRB-\", \"text\": \"(\"}, {\"tag\": \"NN\", \"text\": \"CML\"}, {\"tag\": \"-RRB-\", \"text\": \")\"}, {\"tag\": \",\", \"text\": \",\"}, {\"tag\": \"EX\", \"text\": \"there\"}, {\"tag\": \"VBZ\", \"text\": \"is\"}, {\"tag\": \"JJ\", \"text\": \"mounting\"}, {\"tag\": \"NN\", \"text\": \"evidence\"}, {\"tag\": \"IN\", \"text\": \"that\"}, {\"tag\": \"DT\", \"text\": \"the\"}, {\"tag\": \"NN\", \"text\": \"deregulation\"}, {\"tag\": \"IN\", \"text\": \"of\"}, {\"tag\": \"JJ\", \"text\": \"other\"}, {\"tag\": \"NNS\", \"text\": \"genes\"}, {\"tag\": \",\", \"text\": \",\"}, {\"tag\": \"JJ\", \"text\": \"such\"}, {\"tag\": \"IN\", \"text\": \"as\"}, {\"tag\": \"DT\", \"text\": \"the\"}, {\"tag\": \"NN\", \"text\": \"transcription\"}, {\"tag\": \"NN\", \"text\": \"factor\"}, {\"tag\": \"NN\", \"text\": \"interferon\"}, {\"tag\": \"JJ\", \"text\": \"regulatory\"}, {\"tag\": \"NN\", \"text\": \"factor\"}, {\"tag\": \"CD\", \"text\": \"4\"}, {\"tag\": \"-LRB-\", \"text\": \"(\"}, {\"tag\": \"NN\", \"text\": \"IRF-4\"}, {\"tag\": \"-RRB-\", \"text\": \")\"}, {\"tag\": \",\", \"text\": \",\"}, {\"tag\": \"VBZ\", \"text\": \"is\"}, {\"tag\": \"RB\", \"text\": \"also\"}, {\"tag\": \"VBN\", \"text\": \"implicated\"}, {\"tag\": \"IN\", \"text\": \"in\"}, {\"tag\": \"DT\", \"text\": \"the\"}, {\"tag\": \"NN\", \"text\": \"pathogenesis\"}, {\"tag\": \"IN\", \"text\": \"of\"}, {\"tag\": \"NN\", \"text\": \"CML\"}, {\"tag\": \".\", \"text\": \".\"}]\n",
       "        };\n",
       "\n",
       "        displacy.render(parse, {\n",
       "            uniqueId: 'render_displacy3'\n",
       "            //color: '#ff0000'\n",
       "        });\n",
       "        return {};\n",
       "    });\n",
       "    });\n",
       "    </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio.render_dependencies(event_candidate.sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can learn about the dependency labels in the [Stanford typed dependencies manual](http://nlp.stanford.edu/software/dependencies_manual.pdf). We also provide [lecture notes on dependency parsing](/notebooks/chapters/Transition-based%20dependency%20parsing.ipynb), including various pointers to more information. \n",
    "\n",
    "The `mentions` stores which spans correspond to proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'begin': 2, 'end': 6, 'label': 'Protein'},\n",
       " {'begin': 23, 'end': 24, 'label': 'Protein'},\n",
       " {'begin': 24, 'end': 25, 'label': 'Protein'},\n",
       " {'begin': 59, 'end': 63, 'label': 'Protein'},\n",
       " {'begin': 64, 'end': 65, 'label': 'Protein'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_candidate.sent.mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some convenience functions for the sentence to check all the syntactic parents or children of a token, or whether a specific token is within a protein mention. These can be useful when designing features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(44, 'nsubj')], [(7, 'prep_of'), (20, 'prep_in')])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_candidate.sent.parents[0], event_candidate.sent.children[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_candidate.sent.is_protein[3], event_candidate.sent.is_protein[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels\n",
    "It is useful to know the complete set of event labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Binding',\n",
       " 'Gene_expression',\n",
       " 'Localization',\n",
       " 'Negative_regulation',\n",
       " 'None',\n",
       " 'Phosphorylation',\n",
       " 'Positive_regulation',\n",
       " 'Protein_catabolism',\n",
       " 'Regulation',\n",
       " 'Transcription'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{y for _,y in event_corpus}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 1</font>: Create a Feature Function\n",
    "\n",
    "In this task you will extract a specific feature representation $\\repr(\\x)$ for an event candidate $\\x$. In particular, we want to add as features the syntactic children (modifiers) of the trigger token, together with their syntactic dependency label. A modifier of a token $h$ is a token $m$ that modifies $h$'s meaning. For example, in the noun phrase \"green light\" the adjective \"green\" modifies the noun \"light\". We will refer to the modifier token as the \"child\", and the modified token as \"parent\". Correspondingly, in the dependency graph modifiers are the child nodes of the modified tokens.  \n",
    "\n",
    "The feature function will have to be implemented as a python function that populates a python dictionary with key-value pairs where the key indicates both the word and syntactic label of the child. \n",
    "\n",
    "For example, consider the following event and dependency parse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div id='displacy4' style=\"overflow: scroll; width: 5000px;\"></div>\n",
       "    <script>\n",
       "    $(function() {\n",
       "    requirejs.config({\n",
       "        paths: {\n",
       "            'displaCy': ['/files/node_modules/displacy/displacy'],\n",
       "                                                  // strip .js ^, require adds it back\n",
       "        },\n",
       "    });\n",
       "    require(['displaCy'], function() {\n",
       "        console.log(\"Loaded :)\");\n",
       "        const displacy = new displaCy('http://localhost:8000', {\n",
       "            container: '#displacy4',\n",
       "            format: 'spacy',\n",
       "            distance: 150,\n",
       "            offsetX: 0,\n",
       "            wordSpacing: 20,\n",
       "            arrowSpacing: 3,\n",
       "\n",
       "        });\n",
       "        const parse = {\n",
       "            arcs: [{\"end\": 2, \"label\": \"det\", \"start\": 0, \"dir\": \"left\"}, {\"end\": 2, \"label\": \"nn\", \"start\": 1, \"dir\": \"left\"}, {\"end\": 4, \"label\": \"nsubjpass\", \"start\": 2, \"dir\": \"left\"}, {\"end\": 4, \"label\": \"auxpass\", \"start\": 3, \"dir\": \"left\"}, {\"end\": 10, \"label\": \"det\", \"start\": 6, \"dir\": \"left\"}, {\"end\": 8, \"label\": \"number\", \"start\": 7, \"dir\": \"left\"}, {\"end\": 10, \"label\": \"amod\", \"start\": 8, \"dir\": \"left\"}, {\"end\": 10, \"label\": \"nn\", \"start\": 9, \"dir\": \"left\"}, {\"end\": 10, \"label\": \"prep_on\", \"start\": 4, \"dir\": \"right\"}, {\"end\": 13, \"label\": \"auxpass\", \"start\": 12, \"dir\": \"left\"}, {\"end\": 13, \"label\": \"dep\", \"start\": 4, \"dir\": \"right\"}, {\"end\": 16, \"label\": \"nn\", \"start\": 15, \"dir\": \"left\"}, {\"end\": 16, \"label\": \"prep_with\", \"start\": 13, \"dir\": \"right\"}, {\"end\": 18, \"label\": \"dep\", \"start\": 4, \"dir\": \"right\"}, {\"end\": 18, \"label\": \"conj_and\", \"start\": 13, \"dir\": \"right\"}],\n",
       "            words: [{\"tag\": \"DT\", \"text\": \"The\"}, {\"tag\": \"NN\", \"text\": \"PCR\"}, {\"tag\": \"NNS\", \"text\": \"products\"}, {\"tag\": \"VBD\", \"text\": \"were\"}, {\"tag\": \"VBN\", \"text\": \"electrophoresed\"}, {\"tag\": \"IN\", \"text\": \"on\"}, {\"tag\": \"DT\", \"text\": \"a\"}, {\"tag\": \"CD\", \"text\": \"3\"}, {\"tag\": \"NN\", \"text\": \"%\"}, {\"tag\": \"NN\", \"text\": \"agarose\"}, {\"tag\": \"NN\", \"text\": \"gel\"}, {\"tag\": \",\", \"text\": \",\"}, {\"tag\": \"VBD\", \"text\": \"were\"}, {\"tag\": \"VBN\", \"text\": \"stained\"}, {\"tag\": \"IN\", \"text\": \"with\"}, {\"tag\": \"NN\", \"text\": \"ethidium\"}, {\"tag\": \"NN\", \"text\": \"bromide\"}, {\"tag\": \"CC\", \"text\": \"and\"}, {\"tag\": \"VBN\", \"text\": \"photographed\"}, {\"tag\": \".\", \"text\": \".\"}]\n",
       "        };\n",
       "\n",
       "        displacy.render(parse, {\n",
       "            uniqueId: 'render_displacy4'\n",
       "            //color: '#ff0000'\n",
       "        });\n",
       "        return {};\n",
       "    });\n",
       "    });\n",
       "    </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = event_corpus[398][0]\n",
    "bio.render_dependencies(example.sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the goal is to produce a dictionary that maps the strings \"Child: det->The\" and \"Child: nn->PCR\" to 1.0. \n",
    "\n",
    "To solve this task, implement the feature function below. The passed in `result` is a dictionary you need to populate with more entries, and the `event` argument indicates for which event you need to extract the features. We have already populated the function with some initial code that should get you started.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_dependency_child_feats(result, event):\n",
    "    \"\"\"\n",
    "    Append to the `result` dictionary features based on the syntactic dependencies of the event trigger word of\n",
    "    `event`. The feature keys should have the form \"Child: [label]->[word]\" where \"[label]\" is the syntactic label\n",
    "    of the syntatic child (e.g. \"det\" in the case above), and \"[word]\" is the word of the syntactic child (e.g. \"The\" \n",
    "    in the case above).\n",
    "    Args:\n",
    "        result: a defaultdict that returns `0.0` by default. \n",
    "        event: the event for which we want to populate the `result` dictionary with dependency features.\n",
    "    Returns:\n",
    "        Nothing, but populates the `result` dictionary. \n",
    "    \"\"\"\n",
    "    index = event.trigger_index\n",
    "    if len(event.sent.children[index]) > 0: \n",
    "        for child,label in event.sent.children[index]:\n",
    "            child_name = event.sent.tokens[child]['word']\n",
    "            result[\"Child: \" + label + \"->\" + child_name] += 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 1</font>: Test Feature Function (20 pts)\n",
    "Here we test whether your feature function populates the given dictionary correctly. If the result passes all three tests you get 10 pts. Of course, solutions that just manually populate the result with the specific key value pairs tested below will receive 0 pts as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#! ASSESSMENT 1 - DO NOT CHANGE, MOVE NOR COPY\n",
    "result = defaultdict(float)\n",
    "add_dependency_child_feats(result, example)\n",
    "\n",
    "check_1 = len(result) == 2\n",
    "check_2 = result['Child: det->The'] == 1.0\n",
    "check_3 = result['Child: nn->PCR'] == 1.0\n",
    "(check_1, check_2, check_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Mark</font>:  Your solution to Task 1 is marked with ** __ points**. \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 2</font>: Implement Model\n",
    "\n",
    "You are to implement the `predict_event_labels` function below. This function gets as input a list of event candidate objects, and then returns a sequence of corresponding labels. You can implement this function in any way you like, again utilising any library on the docker image. We have populated the cell and function with a simple implementation that uses the scikit-learn logistic regression model. You can use this as a starting point and focus on implementing better feature functions. You can also start from scratch if you like. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import string\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "# converts labels into integers, and vice versa, needed by scikit-learn.\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# encodes feature dictionaries as numpy vectors, needed by scikit-learn.\n",
    "vectorizer = DictVectorizer()\n",
    "\n",
    "# This list of English stop words is taken from the \"Glasgow Information\n",
    "# Retrieval Group\". The original list can be found at\n",
    "# http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words\n",
    "ENGLISH_STOP_WORDS = frozenset([\n",
    "    \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\",\n",
    "    \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n",
    "    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n",
    "    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n",
    "    \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\",\n",
    "    \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n",
    "    \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\",\n",
    "    \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\",\n",
    "    \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\",\n",
    "    \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\",\n",
    "    \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n",
    "    \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fifty\", \"fill\",\n",
    "    \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\",\n",
    "    \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\",\n",
    "    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n",
    "    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n",
    "    \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n",
    "    \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\",\n",
    "    \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n",
    "    \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n",
    "    \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n",
    "    \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\",\n",
    "    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n",
    "    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n",
    "    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\",\n",
    "    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n",
    "    \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\",\n",
    "    \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\",\n",
    "    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n",
    "    \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n",
    "    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n",
    "    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\",\n",
    "    \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n",
    "    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n",
    "    \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n",
    "    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n",
    "    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n",
    "    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n",
    "    \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n",
    "    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\",\n",
    "    \"yourselves\"])\n",
    "\n",
    "# I used the website http://www.thesaurus.com as an aid to find the following \"negative\" words\n",
    "NEGATIVE_WORDS = ([\"inhibit\",\"constrain\",\"curb\",\"discourag\",\"forbid\", \"hinder\", \"imped\",\n",
    "                  \"obstruct\",\"outlaw\",\"prohibit\",\"restrain\",\"stym\",\"suppress\",\"arrest\",\n",
    "                  \"avert\",\"repress\",\"stop\",\"withhold\",\"bar\",\"block\",\"break\",\"paus\",\n",
    "                  \"reduc\",\"curtail\",\"cut\",\"cut down\",\"diminish\",\"dwindl\",\"lessen\",\n",
    "                  \"lower\",\"par\",\"scale down\",\"shorten\",\"slash\",\"trim\",\"weaken\",\"abat\",\n",
    "                  \"decreas\",\"contract\",\"cutback\",\"declin\",\"shrink\",\"fail\",\"breakdown\",\n",
    "                  \"collaps\",\"defeat\",\"deficiency\",\"deteriorat\",\"loss\",\"misstep\",\"lose\",\n",
    "                  \"failur\"])\n",
    "\n",
    "# The boolean function is_candidate(event, token) checks whether a given token in an event is \n",
    "# part of a candidate argument\n",
    "def is_candidate(event, token):\n",
    "    for candidate in event.argument_candidate_spans[:]:\n",
    "        start = candidate[0]\n",
    "        end = candidate[1]\n",
    "        if token >= start and token < end:\n",
    "            return 1.0 \n",
    "            break\n",
    "    return 0\n",
    "\n",
    "# The function add_dependency_child_feats2(result, event) assigns a variety of children dependency \n",
    "# features to a given observation\n",
    "def add_dependency_child_feats2(result, event, trigger_word, index, trigger_pos):\n",
    "    flag1 = True \n",
    "    flag2 = True\n",
    "    if len(event.sent.children[index]) > 0: \n",
    "        for child,label in event.sent.children[index]:\n",
    "            child_name = event.sent.tokens[child]['word']\n",
    "            result[\"Child: \" + label + \"->\" + child_name] += 1.0\n",
    "            result[\"Child_dependency_type: \" + label] += 1.0\n",
    "            pos = event.sent.tokens[child]['pos']\n",
    "            result[\"Child_pos: \" + pos] += 1.0\n",
    "            result[\"Child_pos_dependency: \" + pos + \" \" + label] += 1.0\n",
    "            if flag1 and event.sent.is_protein[child]:\n",
    "                result[\"Has_child_protein: \"] = event.sent.is_protein[child]\n",
    "                flag1 = False\n",
    "            result[\"Child_protein: \" + child_name] += event.sent.is_protein[child]\n",
    "            result[\"Child_candidate: \" + child_name] += is_candidate(event, child)\n",
    "            # Tried Feature: result[\"Trigger_Protein: \" + trigger_word + child_name] += event.sent.is_protein[child]\n",
    "            result[\"Trigger_Candidate: \" + trigger_word + child_name] += is_candidate(event, child)\n",
    "            if event.sent.is_protein[child] and is_candidate(event, child):\n",
    "                result[\"Both_protein_and_candidate: \"] = 1\n",
    "            if event.sent.is_protein[child]:\n",
    "                result[\"Child_protein_path: \" + trigger_pos + label + pos] += 1.0\n",
    "            if len(event.sent.children[child]) > 0:  \n",
    "                for grand_child, grand_child_label in event.sent.children[child]:\n",
    "                    if flag2 and event.sent.is_protein[grand_child]:\n",
    "                        result[\"Has_grand_child_protein: \"] = event.sent.is_protein[grand_child]\n",
    "                        flag2 = False\n",
    "                    grand_pos = event.sent.tokens[grand_child]['pos']\n",
    "                    result[\"Grand_child_pos: \" + grand_pos] += 1.0\n",
    "                    result[\"Grand_child_dependency: \" + grand_pos + \" \" + grand_child_label] += 1.0\n",
    "                    grand_child_name = event.sent.tokens[grand_child]['word'] \n",
    "                    #Tried Features:\n",
    "                    #result[\"Path: \" + label + \"->\" + child_name + \"->\" + grand_child_label + \"->\" + grand_child_name]\n",
    "                    #result[\"Dep_path: \" + trigger_pos + \"->\" + label + \"->\" + pos + \"->\" + grand_child_label + \"->\" + grand_pos]\n",
    "                    #result[\"Path: \" + label + \"->\" + grand_child_label]\n",
    "                    result[\"Grand_child_candidate: \" + grand_child_name] += is_candidate(event, grand_child)\n",
    "                    if event.sent.is_protein[grand_child]:\n",
    "                        result[\"Grand_child_protein_path: \" + trigger_pos + \"->\" + label + \"->\" + pos + \"->\" + grand_child_label + \"->\" + grand_pos] += 1.0\n",
    "                        # Tried Feature\n",
    "                        #result[\"Grand_child_protein_word_path: \" + trigger_word + child_name + grand_child_name] += 1\n",
    "\n",
    "# The function add_dependency_parents_feats2(result, event) assigns a variety of parents dependency \n",
    "# features to a given observation\n",
    "def add_dependency_parents_feats2(result, event, trigger_word, index, trigger_pos):\n",
    "    flag1 = True \n",
    "    flag2 = True\n",
    "    if len(event.sent.parents[index]) > 0: \n",
    "        for parent,label in event.sent.parents[index]:\n",
    "            parent_name = event.sent.tokens[parent]['word']\n",
    "            result[\"Parent: \" + label + \"<-\" + parent_name] += 1.0\n",
    "            result[\"Parent_dependency_type: \" + label] += 1.0\n",
    "            pos = event.sent.tokens[parent]['pos']\n",
    "            result[\"Parent_pos: \" + pos] += 1.0\n",
    "            result[\"Parent_pos_dependency: \" + pos + \" \" + label] += 1.0\n",
    "            if flag1 and event.sent.is_protein[parent]:\n",
    "                result[\"Has_parent_protein: \"] = event.sent.is_protein[parent]\n",
    "                flag1 = False\n",
    "            # Tried Feature:\n",
    "            #if event.sent.is_protein[parent]:\n",
    "            #    result[\"Parent_protein_path: \" + pos + label + trigger_pos] += 1.0\n",
    "            if len(event.sent.parents[parent]) > 0:  \n",
    "                for grand_parent, grand_parent_label in event.sent.parents[parent]:\n",
    "                    if flag2 and event.sent.is_protein[grand_parent]:\n",
    "                        result[\"Has_grand_parent_protein: \"] = event.sent.is_protein[grand_parent]\n",
    "                        flag2 = False\n",
    "                    #Tried Features \n",
    "                    #grand_pos = event.sent.tokens[grand_parent]['pos']\n",
    "                    #result[\"Grand_parent_pos: \" + grand_pos] += 1.0\n",
    "                    #result[\"Grand_parent_dependency: \" + grand_pos + \" \" + grand_parent_label] += 1.0 \n",
    "                    \n",
    "\n",
    "# The function get_rid_of_stem_feat(result, event, trigger_word, trigger_stem) gets rid \n",
    "# of the trigger word's stem and uses the remaining part as a feature\n",
    "def get_rid_of_stem_feat(result, event, trigger_word, trigger_stem):\n",
    "    word_length = len(trigger_word)\n",
    "    stem_length = len(trigger_stem)\n",
    "    rest_trigger = trigger_word[stem_length:word_length]\n",
    "    result[\"Rest_trigger: \" + rest_trigger] += 1.0\n",
    "    #result[\"Is_gerund: \"] = (rest_trigger == \"ing\")\n",
    "\n",
    "# The function has_capital(result, trigger_word) checks whether the trigger word has a \n",
    "# capital letter and uses that as a feature\n",
    "def has_capital(result, trigger_word):\n",
    "    trigger_lower = trigger_word.lower()\n",
    "    result[\"Has_capital: \"] = not(trigger_word == trigger_lower)\n",
    "    \n",
    "# The function has_number(result, trigger_word) checks whether the trigger word \n",
    "# contains any number and uses that as a feature \n",
    "def has_number(result, trigger_word):\n",
    "    result[\"Has_number: \"] = any(char.isdigit() for char in trigger_word)\n",
    "\n",
    "# The function has_symbol(result, trigger_word) checks whether the trigger word \n",
    "# has \"-\", \"/\" or \"\\\" in it and uses that as a feature\n",
    "def has_symbol(result, trigger_word):\n",
    "    result[\"Has_symbol: \"] = ((\"-\" in trigger_word) or (\"/\" in trigger_word)) or (\"\\\\\" in trigger_word)\n",
    "\n",
    "# The function is_short(result,event, trigger_word) checks whether the trigger word \n",
    "# is \"short\" (i.e. 3 characters or less) or \"very short\" (i.e. 2 characters or less)\n",
    "# and uses that as a feature\n",
    "def is_short(result, event, trigger_word, index):\n",
    "    if not(event.sent.is_protein[index]):\n",
    "        result[\"Is_short: \"] = (len(trigger_word) <= 3) \n",
    "        result[\"Is_very_short: \"] = (len(trigger_word) <= 2) \n",
    "\n",
    "# The function add_bag_of_words(result, event) creates a bag of words for a given \n",
    "# observation and uses that as a feature\n",
    "def add_bag_of_words(result, event):\n",
    "    for i in event.sent.tokens:\n",
    "        result[\"Token: \" + i[\"word\"]] += 1 \n",
    "\n",
    "# The function is_stop_word(result, trigger_word) checks whether the trigger word \n",
    "# is a stop word and uses that as a feature \n",
    "def is_stop_word(result, trigger_word):\n",
    "    result[\"Is_stop_word: \"] = (trigger_word in ENGLISH_STOP_WORDS)\n",
    "\n",
    "# The function consecutive_grams(result,event,index) adds consecutive n-grams features\n",
    "def consecutive_grams(result, event, index):\n",
    "    if index - 1 >= 0:\n",
    "        result[\"Trigger_minus_1: \" + event.sent.tokens[index-1][\"stem\"]] += 1\n",
    "        result[\"Trigger_minus_1_pos: \" + event.sent.tokens[index-1][\"pos\"]] += 1\n",
    "    else:\n",
    "        result[\"Trigger_minus_1: \"] += 1\n",
    "        result[\"Trigger_minus_1_pos: \"] += 1\n",
    "    # Tried Feature:\n",
    "    #result[\"Trigger_minus_1_tot: \" + event.sent.tokens[index-1][\"stem\"] + \" \" + event.sent.tokens[index-1][\"pos\"]] += 1\n",
    "    if index + 1 < len(event.sent.tokens):\n",
    "        result[\"Trigger_plus_1: \" + event.sent.tokens[index+1][\"stem\"]] += 1\n",
    "        result[\"Trigger_plus_1_pos: \" + event.sent.tokens[index+1][\"pos\"]] += 1\n",
    "    else:\n",
    "        result[\"Trigger_plus_1: \"] += 1\n",
    "        result[\"Trigger_plus_1_pos: \"] += 1\n",
    "\n",
    "# The function make_protein_name(event_candidate, begin, end) returns the \n",
    "# protein name starting at token \"begin\" and ending at token \"end-1\" \n",
    "def make_protein_name(event_candidate, begin, end):\n",
    "    name = \"\"\n",
    "    for i in range(begin,end):\n",
    "        if i == begin:\n",
    "            name = name + str(event_candidate.sent.tokens[i]['word'])\n",
    "        else:\n",
    "            name = name + \" \" + str(event_candidate.sent.tokens[i]['word']) \n",
    "    return name \n",
    "\n",
    "# The function add_proteins_feats(result, event) adds a string feature that \n",
    "# results from the concatenation of all of the protein names appearing in \n",
    "# a given observation/event.\n",
    "def add_proteins_feats(result, event):\n",
    "    if len(event.sent.mentions) > 0:\n",
    "        protein_name = \"\"\n",
    "        for i in event.sent.mentions:\n",
    "            begin = i['begin']\n",
    "            end = i['end']\n",
    "            protein_name = protein_name + make_protein_name(event, begin, end)\n",
    "        result[\"Protein: \" + protein_name] += 1.0 \n",
    "\n",
    "# The function max_children_word(result,event) finds the token with the \n",
    "# maximum number of children for a given observation and uses that as a \n",
    "# feature\n",
    "def max_children_word(result, event):\n",
    "    max_children = 0;\n",
    "    max_index = 0;\n",
    "    for index in range(len(event.sent.tokens)):\n",
    "        num_children = len(event.sent.children[index])\n",
    "        if num_children > max_children:\n",
    "            max_children = num_children\n",
    "            max_index = index\n",
    "    result[\"Max_children_word: \" + event.sent.tokens[max_index][\"word\"]] += 1\n",
    "    # Tried Feature:\n",
    "    #result[\"Max_children_word_pos: \" + event.sent.tokens[max_index][\"pos\"]] += 1\n",
    "\n",
    "# The function has_dependencies(result,event,index) checks whether the \n",
    "# trigger word has any parents or children and uses that as a feature\n",
    "def has_dependencies(result, event, index):\n",
    "    result[\"Has_children: \"] = (len(event.sent.children[index])>0)\n",
    "    result[\"Has_parents: \"] = (len(event.sent.parents[index])>0)\n",
    "\n",
    "# The function count_dependencies(result, event, index) counts the \n",
    "# number of parents and children of a trigger word and uses these \n",
    "# numbers as features\n",
    "def count_dependencies(result, event, index):\n",
    "    result[\"Has_children: \"] = len(event.sent.children[index])\n",
    "    result[\"Has_parents: \"] = len(event.sent.parents[index])\n",
    "\n",
    "# The function is_punctuation(result, trigger_word) checks whether the \n",
    "# trigger word is a punctuation symbol and uses that as a feature\n",
    "def is_punctuation(result, trigger_word):\n",
    "    result[\"Is_punctuation: \"] = (trigger_word in string.punctuation)\n",
    "\n",
    "# The function number_of_proteins(result, event, index) counts the number of \n",
    "# proteins in an event and uses that as a feature\n",
    "def number_of_proteins(result, event, index):\n",
    "    result[\"Number_of_proteins: \" + event.sent.tokens[index][\"word\"]] += len(event.sent.mentions)\n",
    "    # Tried Feature:\n",
    "    #result[\"Protein_count: \"] += len(event.sent.mentions)\n",
    "\n",
    "# The function number_of_arguments(result, event) counts the number of \n",
    "# candidate arguments in an event and uses that as a feature\n",
    "def number_of_arguments(result, event):\n",
    "    result[\"Number_of_arguments: \"] = len(event.argument_candidate_spans)\n",
    "\n",
    "# The function make_sentence(event) returns a string corresponding to a given event \n",
    "def make_sentence(event):\n",
    "    sentence = \"\"\n",
    "    for token in event.sent.tokens:\n",
    "        sentence = sentence + token[\"word\"].lower()\n",
    "    return sentence\n",
    "    \n",
    "# The function label_feature(result, event) checks whether any of the labels \n",
    "# (except \"None\") appear in the event and uses that as a feature    \n",
    "def label_feature(result, event, sentence):\n",
    "    if \"binding\" in sentence:\n",
    "        result[\"Binding: \"] += 1\n",
    "    if \"gene expression\" in sentence:\n",
    "        result[\"Gene_expression: \"] += 1\n",
    "    if \"localization\" in sentence:\n",
    "        result[\"Localization: \"] += 1\n",
    "    if \"negative regulation\" in sentence:\n",
    "        result[\"Negative_regulation: \"] += 1\n",
    "    if \"phosphorylation\" in sentence:\n",
    "        result[\"Phosphorylation: \"] += 1\n",
    "    if \"positive regulation\" in sentence:\n",
    "        result[\"Positive_regulation: \"] += 1\n",
    "    if \"protein catabolism\" in sentence:\n",
    "        result[\"Protein_catabolism: \"] += 1\n",
    "    if \"regulation\" in sentence:\n",
    "        result[\"regulation: \"] += 1\n",
    "    if \"transcription\" in sentence:\n",
    "        result[\"Transcription: \"] += 1\n",
    "\n",
    "# The function check_negatives(result, event) checks whether one of the following \"negative\" \n",
    "# words appear in the sentence: \"negative\", \"no\" or \"not\". This check is then used as a \n",
    "# feature\n",
    "def check_negatives(result, event, sentence):\n",
    "    if (\"negative\" in sentence) or (\"no\" in sentence) or (\"not\" in sentence):\n",
    "        result[\"Negative: \"] += 1\n",
    "\n",
    "# The function none_like(result, event, trigger_word, index) checks whether the trigger word \n",
    "# is a none-like word (i.e. likely to correspond to a \"None\" output) and uses that as a feature\n",
    "# In particular, it checks whether the trigger word \n",
    "# - has children or parents dependencies \n",
    "# - is \"short\" (less than 3 characters)\n",
    "# - contains the symbols \"-\", \"/\" or \"\\\"\n",
    "def none_like(result, event, trigger_word, index):\n",
    "    l_c = len(event.sent.children[index])\n",
    "    l_p = len(event.sent.parents[index])\n",
    "    len_trigger = len(trigger_word)\n",
    "    if l_c == 0 and l_p == 0 and len_trigger <= 3 and not(((\"-\" in trigger_word) or (\"/\" in trigger_word)) or (\"\\\\\" in trigger_word)):\n",
    "        result[\"None_like: \"] += 1\n",
    "\n",
    "# The function get_top_head(head, event, visited) is the \"recursive implementation\" of the function that \n",
    "# returns the path between the trigger word and one of its top ancestors. It might return a partial path \n",
    "# in case of loops. \n",
    "def get_top_head(head, event, visited):\n",
    "    if len(event.sent.parents[head]) == 0:\n",
    "        path = event.sent.tokens[head][\"pos\"]\n",
    "        return path\n",
    "    else:\n",
    "        parent, label = event.sent.parents[head][0]\n",
    "        print(parent)\n",
    "        if parent in visited:\n",
    "            return \"\"\n",
    "        else:\n",
    "            visited.append(parent)\n",
    "            path = event.sent.tokens[head][\"pos\"] + \"->\" + label + \"->\" + get_top_head(parent,event,visited)\n",
    "            return path\n",
    "\n",
    "# The function get_top_head_while(head, event) is the \"while implementation\" of the function that \n",
    "# returns the path between the trigger word and one of its top ancestors. It might return a \n",
    "# partial path in case of loops. \n",
    "def get_top_head_while(head, event):\n",
    "    path = event.sent.tokens[head][\"pos\"]\n",
    "    visited = []\n",
    "    while len(event.sent.parents[head]) > 0 and head not in visited:\n",
    "        parent, label = event.sent.parents[head][0]\n",
    "        visited.append(parent)\n",
    "        path = path + \"->\" + label + \"->\" + event.sent.tokens[parent][\"pos\"]\n",
    "        head = parent\n",
    "    return path\n",
    "\n",
    "# The function get_number_of_arcs(path) returns the number of arcs in the string path\n",
    "def get_number_of_arcs(path):\n",
    "    return path.count(\"->\")/2\n",
    "\n",
    "# The function top_head_feature(result, event, index) gets the dependency distance from \n",
    "# the trigger word to one of its top ancestors. It might return a partial path in case of loops.\n",
    "def top_head_feature(result, event, index):\n",
    "    top_path = get_top_head_while(index, event)\n",
    "    result[\"Top_head_distance: \"] += get_number_of_arcs(top_path)\n",
    "    result[\"Top_Path: \" + top_path] += 1\n",
    "    \n",
    "def event_feat(event):\n",
    "    \"\"\"\n",
    "    This feature function returns a dictionary representation of the event candidate. You can improve the model \n",
    "    by improving this feature function.\n",
    "    Args:\n",
    "        event: the `EventCandidate` object to produce a feature dictionary for.\n",
    "    Returns:\n",
    "        a dictionary with feature keys/indices mapped to feature counts.\n",
    "    \"\"\"\n",
    "    result = defaultdict(float)\n",
    "    \n",
    "    # Create the string sentence for the event\n",
    "    sentence = make_sentence(event)\n",
    "    \n",
    "    # Trigger word name\n",
    "    trigger_word = event.sent.tokens[event.trigger_index]['word']\n",
    "    \n",
    "    # Trigger word's index\n",
    "    index = event.trigger_index\n",
    "    \n",
    "    # Trigger word's part of speech\n",
    "    trigger_pos = event.sent.tokens[index]['pos']\n",
    "    \n",
    "    # Trigger words's stem \n",
    "    trigger_stem = event.sent.tokens[index]['stem']\n",
    "    \n",
    "    # Feature 1: Token \n",
    "    result['trigger_word=' + trigger_word] += 1.0\n",
    "    \n",
    "    # Feature 2: Part of speech of the token \n",
    "    result['trigger_word_pos=' + trigger_pos] += 1.0\n",
    "    \n",
    "    # Feature 3: Stem of the word\n",
    "    result['trigger_word_stem=' + trigger_stem] += 1.0\n",
    "    \n",
    "    # Tried Feature: Check whether the trigger word is part of a protein\n",
    "    # result['Is_trigger_protein: '] = event.sent.is_protein[event.trigger_index]\n",
    "    \n",
    "    # Feature 4: Get rid of the trigger word's stem and use the remaining part\n",
    "    get_rid_of_stem_feat(result, event, trigger_word, trigger_stem)\n",
    "    \n",
    "    # Feature 5: Check whether the trigger word has a capital letter \n",
    "    has_capital(result, trigger_word)\n",
    "    \n",
    "    # Feature 6: Check whether the trigger word has a number\n",
    "    has_number(result, trigger_word)\n",
    "    \n",
    "    # Feature 7: Check whether the trigger word has one of these symbols: \"-\", \"/\" or \"\\\"\n",
    "    has_symbol(result, trigger_word)\n",
    "    \n",
    "    # Features 8 and 9: Check whether the trigger word is \"short\" and \"very short\" (i.e. bigram or trigram)\n",
    "    is_short(result, event, trigger_word, index) \n",
    "    \n",
    "    # Tried Feature: Add a bag of words features\n",
    "    # add_bag_of_words(result, event)\n",
    "    \n",
    "    # Feature 10: Check whether the trigger word is a stop word\n",
    "    is_stop_word(result, trigger_word)\n",
    "    \n",
    "    # Features 11-18: Add consecutive n-grams features\n",
    "    consecutive_grams(result, event, index)\n",
    "    \n",
    "    # Tried Feature: Find the word in the event with the maximum number of children \n",
    "    # max_children_word(result,event)\n",
    "    \n",
    "    # Features 19-20: Check whether the trigger word has dependencies (i.e. parents or children)\n",
    "    has_dependencies(result, event, index)\n",
    "    \n",
    "    # Tried Feature: Count the number of dependencies (i.e. number of parents and children) of the trigger word\n",
    "    # count_dependencies(result,event,index)\n",
    "    \n",
    "    # Tried Feature: Check whether the trigger word is the first word of the event \n",
    "    # result[\"Is_first_word: \"] += (event.trigger_index == 0)\n",
    "    \n",
    "    # Tried Feature: Check whether the trigger word is a punctuation symbol \n",
    "    # is_punctuation(result, trigger_word)\n",
    "    \n",
    "    # Feature 21: Count the number of proteins in a given event\n",
    "    number_of_proteins(result, event, index)\n",
    "    \n",
    "    # Feature 22: Count the number of candidate arguments in a given event\n",
    "    number_of_arguments(result, event)\n",
    "    \n",
    "    # Features 23-31: Check whether any of the labels (except \"None\") appear in the event\n",
    "    label_feature(result, event, sentence)\n",
    "    \n",
    "    # Feature 32: Check for a \"negative\" word, i.e. \"negative\", \"no\" or \"not\" in the event\n",
    "    check_negatives(result, event, sentence)\n",
    "    \n",
    "    # Feature 33: Check whether the stem of the trigger word is in the \"inhibition/decrease/negative\" list of words \n",
    "    # above, i.e. NEGATIVE_WORDS \n",
    "    result[\"Is_trigger_negative: \"] = (event.sent.tokens[event.trigger_index]['stem'].lower() in NEGATIVE_WORDS)\n",
    "    \n",
    "    # Tried feature: Get the dependency distance from the trigger word to one of its top ancestors. It might return a \n",
    "    # partial path in case of loops\n",
    "    # top_head_feature(result, event, index)\n",
    "    \n",
    "    # Tried Feature: string feature that results from the concatenation of all of the protein names appearing in \n",
    "    # a given observation/event. \n",
    "    # add_proteins_feats(result, event)\n",
    "    \n",
    "    # Features 34-48: Add children dependencies features of the trigger word \n",
    "    add_dependency_child_feats2(result, event, trigger_word, index, trigger_pos)\n",
    "    \n",
    "    # Features 49-54: Add parents dependencies features of the trigger word\n",
    "    add_dependency_parents_feats2(result, event, trigger_word, index, trigger_pos)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# We convert the event candidates and their labels into vectors and integers, respectively.\n",
    "train_event_x = vectorizer.fit_transform([event_feat(x) for x,_ in event_train])\n",
    "train_event_y = label_encoder.fit_transform([y for _,y in event_train])\n",
    "\n",
    "# Create and train the model. Feel free to experiment with other parameters and learners.\n",
    "lr = LogisticRegression(C=2.3, class_weight=\"balanced\") # Optimized C parameter: 2.3\n",
    "lr.fit(train_event_x, train_event_y)\n",
    "\n",
    "def predict_event_labels(event_candidates):\n",
    "    \"\"\"\n",
    "    This function receives a list of `bio.EventCandidate` objects and predicts their labels. \n",
    "    It is currently implemented using scikit-learn, but you are free to replace it with any other\n",
    "    implementation as long as you fulfil its contract.\n",
    "    Args:\n",
    "        event_candidates: A list of `EventCandidate` objects to label.\n",
    "    Returns:\n",
    "        a list of event labels, where the i-th label belongs to the i-th event candidate in the input.\n",
    "    \"\"\"\n",
    "    event_x = vectorizer.transform([event_feat(e) for e in event_candidates])\n",
    "    event_y = label_encoder.inverse_transform(lr.predict(event_x))\n",
    "    return event_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is useful to inspect the performance of your model, and see where it makes errors, both on the training set (to check for underfitting) and the development set. We have provided you with utility functions to help with this inspection. Note that you don't have to use these utilities, or the cells below, but it can help you to improve your model, and also with the error analysis and description of the approach in Task 3. \n",
    "\n",
    "First, we give you a breakdown of precision, recall and F1 on different event types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Guess</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Binding</td>\n",
       "      <td>180</td>\n",
       "      <td>198</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.645503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gene_expression</td>\n",
       "      <td>377</td>\n",
       "      <td>389</td>\n",
       "      <td>0.796915</td>\n",
       "      <td>0.822281</td>\n",
       "      <td>0.809399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Localization</td>\n",
       "      <td>71</td>\n",
       "      <td>61</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative_regulation</td>\n",
       "      <td>210</td>\n",
       "      <td>218</td>\n",
       "      <td>0.614679</td>\n",
       "      <td>0.638095</td>\n",
       "      <td>0.626168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phosphorylation</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Positive_regulation</td>\n",
       "      <td>570</td>\n",
       "      <td>637</td>\n",
       "      <td>0.574568</td>\n",
       "      <td>0.642105</td>\n",
       "      <td>0.606462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Protein_catabolism</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Regulation</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>0.540107</td>\n",
       "      <td>0.537234</td>\n",
       "      <td>0.538667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Transcription</td>\n",
       "      <td>112</td>\n",
       "      <td>114</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.601770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[All]</td>\n",
       "      <td>1761</td>\n",
       "      <td>1855</td>\n",
       "      <td>0.639892</td>\n",
       "      <td>0.674049</td>\n",
       "      <td>0.656527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Label  Gold  Guess  Precision    Recall        F1\n",
       "0              Binding   180    198   0.616162  0.677778  0.645503\n",
       "1      Gene_expression   377    389   0.796915  0.822281  0.809399\n",
       "2         Localization    71     61   0.721311  0.619718  0.666667\n",
       "3  Negative_regulation   210    218   0.614679  0.638095  0.626168\n",
       "4      Phosphorylation    32     28   0.928571  0.812500  0.866667\n",
       "5  Positive_regulation   570    637   0.574568  0.642105  0.606462\n",
       "6   Protein_catabolism    21     23   0.695652  0.761905  0.727273\n",
       "7           Regulation   188    187   0.540107  0.537234  0.538667\n",
       "8        Transcription   112    114   0.596491  0.607143  0.601770\n",
       "9                [All]  1761   1855   0.639892  0.674049  0.656527"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This line calls your function to produce labels for the test set\n",
    "event_dev_guess = predict_event_labels([x for x,_ in event_dev[:]])\n",
    "# This line produces a confusion matrix\n",
    "cm_dev = bio.create_confusion_matrix(event_dev,event_dev_guess)  \n",
    "# This line turns the confusion matrix into a evaluation table with Precision, Recall and F1 for all labels.\n",
    "bio.full_evaluation_table(cm_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is useful to inspect [bio.py](/edit/statnlpbook/bio.py) to see how we define precision, recall and F1 score in this context.\n",
    "\n",
    "You can also display a confusion matrix to identify what types of errors you are currently making. Notice that the matrix ignores the \"None\"-\"None\" cell as its counts would overpower all other counts (try removing the `outside_label` argument). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAAEZCAYAAAAEzefsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOskOT/OhigAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f51443157b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import statnlpbook.util as util\n",
    "util.plot_confusion_matrix_dict(cm_dev,90, outside_label=\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix can give you hints on what type of errors you should look for and improve upon. This macro view on your model's performance is often more powerful when combined with a micro view on the instances that produce these errors. You can find errors of a specific type using `bio.find_errors` as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<statnlpbook.bio.EventCandidate at 0x7f51195ccb00>, 'Transcription', 'None'),\n",
       " (<statnlpbook.bio.EventCandidate at 0x7f5119590b00>, 'Transcription', 'None'),\n",
       " (<statnlpbook.bio.EventCandidate at 0x7f5119597278>, 'Transcription', 'None')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = bio.find_errors(\"Transcription\",\"None\", event_dev, event_dev_guess)[:3]\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These errors you can then inspect in detail via `show_event_error`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Gold</th>\n",
       "      <th>Guess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Transcription</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>The <font color='red'>[</font><font color='blue'>[LAZ3]</font><font color='red'>]</font> <font color='red'>[</font><font color='blue'>[/BCL6]</font><font color='red'>]</font> <font color='red'>[</font>transcript<font color='red'>]</font> was <font color='green'>found</font> in a variety <font color='red'>[</font>of<font color='red'>]</font> tissues , <font color='red'>[</font>including<font color='red'>]</font> skeletal muscle , peripheral blood leukocytes , and <font color='red'>[</font>weakly<font color='red'>]</font> in normal lymph nodes .\n",
       "    <div id='displacy5' style=\"overflow: scroll; width: 5000px;\"></div>\n",
       "    <script>\n",
       "    $(function() {\n",
       "    requirejs.config({\n",
       "        paths: {\n",
       "            'displaCy': ['/files/node_modules/displacy/displacy'],\n",
       "                                                  // strip .js ^, require adds it back\n",
       "        },\n",
       "    });\n",
       "    require(['displaCy'], function() {\n",
       "        console.log(\"Loaded :)\");\n",
       "        const displacy = new displaCy('http://localhost:8000', {\n",
       "            container: '#displacy5',\n",
       "            format: 'spacy',\n",
       "            distance: 150,\n",
       "            offsetX: 0,\n",
       "            wordSpacing: 20,\n",
       "            arrowSpacing: 3,\n",
       "\n",
       "        });\n",
       "        const parse = {\n",
       "            arcs: [{\"end\": 3, \"label\": \"det\", \"start\": 0, \"dir\": \"left\"}, {\"end\": 3, \"label\": \"nn\", \"start\": 1, \"dir\": \"left\"}, {\"end\": 3, \"label\": \"nn\", \"start\": 2, \"dir\": \"left\"}, {\"end\": 5, \"label\": \"nsubjpass\", \"start\": 3, \"dir\": \"left\"}, {\"end\": 5, \"label\": \"auxpass\", \"start\": 4, \"dir\": \"left\"}, {\"end\": 8, \"label\": \"det\", \"start\": 7, \"dir\": \"left\"}, {\"end\": 8, \"label\": \"prep_in\", \"start\": 5, \"dir\": \"right\"}, {\"end\": 10, \"label\": \"prep_of\", \"start\": 8, \"dir\": \"right\"}, {\"end\": 14, \"label\": \"amod\", \"start\": 13, \"dir\": \"left\"}, {\"end\": 14, \"label\": \"prep_including\", \"start\": 10, \"dir\": \"right\"}, {\"end\": 18, \"label\": \"amod\", \"start\": 16, \"dir\": \"left\"}, {\"end\": 18, \"label\": \"nn\", \"start\": 17, \"dir\": \"left\"}, {\"end\": 18, \"label\": \"appos\", \"start\": 14, \"dir\": \"right\"}, {\"end\": 21, \"label\": \"prep_including\", \"start\": 10, \"dir\": \"right\"}, {\"end\": 21, \"label\": \"conj_and\", \"start\": 14, \"dir\": \"right\"}, {\"end\": 25, \"label\": \"amod\", \"start\": 23, \"dir\": \"left\"}, {\"end\": 25, \"label\": \"nn\", \"start\": 24, \"dir\": \"left\"}, {\"end\": 25, \"label\": \"prep_in\", \"start\": 21, \"dir\": \"right\"}],\n",
       "            words: [{\"tag\": \"DT\", \"text\": \"The\"}, {\"tag\": \"NN\", \"text\": \"LAZ3\"}, {\"tag\": \"NN\", \"text\": \"/BCL6\"}, {\"tag\": \"NN\", \"text\": \"transcript\"}, {\"tag\": \"VBD\", \"text\": \"was\"}, {\"tag\": \"VBN\", \"text\": \"found\"}, {\"tag\": \"IN\", \"text\": \"in\"}, {\"tag\": \"DT\", \"text\": \"a\"}, {\"tag\": \"NN\", \"text\": \"variety\"}, {\"tag\": \"IN\", \"text\": \"of\"}, {\"tag\": \"NNS\", \"text\": \"tissues\"}, {\"tag\": \",\", \"text\": \",\"}, {\"tag\": \"VBG\", \"text\": \"including\"}, {\"tag\": \"JJ\", \"text\": \"skeletal\"}, {\"tag\": \"NN\", \"text\": \"muscle\"}, {\"tag\": \",\", \"text\": \",\"}, {\"tag\": \"JJ\", \"text\": \"peripheral\"}, {\"tag\": \"NN\", \"text\": \"blood\"}, {\"tag\": \"NNS\", \"text\": \"leukocytes\"}, {\"tag\": \",\", \"text\": \",\"}, {\"tag\": \"CC\", \"text\": \"and\"}, {\"tag\": \"RB\", \"text\": \"weakly\"}, {\"tag\": \"IN\", \"text\": \"in\"}, {\"tag\": \"JJ\", \"text\": \"normal\"}, {\"tag\": \"NN\", \"text\": \"lymph\"}, {\"tag\": \"NNS\", \"text\": \"nodes\"}, {\"tag\": \".\", \"text\": \".\"}]\n",
       "        };\n",
       "\n",
       "        displacy.render(parse, {\n",
       "            uniqueId: 'render_displacy5'\n",
       "            //color: '#ff0000'\n",
       "        });\n",
       "        return {};\n",
       "    });\n",
       "    });\n",
       "    </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio.show_event_error(*errors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can also be very useful to inspect your feature map for the given instance. Sometimes this leads you to find out that you have a bug in your feature calculation, or that the feature representation is still insufficient for other reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'Child: auxpass->was': 1.0,\n",
       "             'Child: nsubjpass->transcript': 1.0,\n",
       "             'Child: prep_in->variety': 1.0,\n",
       "             'Child_candidate: transcript': 1.0,\n",
       "             'Child_candidate: variety': 0.0,\n",
       "             'Child_candidate: was': 0.0,\n",
       "             'Child_dependency_type: auxpass': 1.0,\n",
       "             'Child_dependency_type: nsubjpass': 1.0,\n",
       "             'Child_dependency_type: prep_in': 1.0,\n",
       "             'Child_pos: NN': 2.0,\n",
       "             'Child_pos: VBD': 1.0,\n",
       "             'Child_pos_dependency: NN nsubjpass': 1.0,\n",
       "             'Child_pos_dependency: NN prep_in': 1.0,\n",
       "             'Child_pos_dependency: VBD auxpass': 1.0,\n",
       "             'Child_protein: transcript': 0.0,\n",
       "             'Child_protein: variety': 0.0,\n",
       "             'Child_protein: was': 0.0,\n",
       "             'Grand_child_candidate: /BCL6': 1.0,\n",
       "             'Grand_child_candidate: LAZ3': 1.0,\n",
       "             'Grand_child_candidate: The': 0.0,\n",
       "             'Grand_child_candidate: a': 0.0,\n",
       "             'Grand_child_candidate: tissues': 0.0,\n",
       "             'Grand_child_dependency: DT det': 2.0,\n",
       "             'Grand_child_dependency: NN nn': 2.0,\n",
       "             'Grand_child_dependency: NNS prep_of': 1.0,\n",
       "             'Grand_child_pos: DT': 2.0,\n",
       "             'Grand_child_pos: NN': 2.0,\n",
       "             'Grand_child_pos: NNS': 1.0,\n",
       "             'Grand_child_protein_path: VBN->nsubjpass->NN->nn->NN': 2.0,\n",
       "             'Has_capital: ': False,\n",
       "             'Has_children: ': True,\n",
       "             'Has_grand_child_protein: ': True,\n",
       "             'Has_number: ': False,\n",
       "             'Has_parents: ': False,\n",
       "             'Has_symbol: ': False,\n",
       "             'Is_short: ': False,\n",
       "             'Is_stop_word: ': True,\n",
       "             'Is_trigger_negative: ': False,\n",
       "             'Is_very_short: ': False,\n",
       "             'Negative: ': 1.0,\n",
       "             'Number_of_arguments: ': 6,\n",
       "             'Number_of_proteins: found': 2.0,\n",
       "             'Rest_trigger: ': 1.0,\n",
       "             'Trigger_Candidate: foundtranscript': 1.0,\n",
       "             'Trigger_Candidate: foundvariety': 0.0,\n",
       "             'Trigger_Candidate: foundwas': 0.0,\n",
       "             'Trigger_minus_1: was': 1.0,\n",
       "             'Trigger_minus_1_pos: VBD': 1.0,\n",
       "             'Trigger_plus_1: in': 1.0,\n",
       "             'Trigger_plus_1_pos: IN': 1.0,\n",
       "             'trigger_word=found': 1.0,\n",
       "             'trigger_word_pos=VBN': 1.0,\n",
       "             'trigger_word_stem=found': 1.0})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_feat(errors[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 2</font>: Assess Accuracy (50 pts) \n",
    "\n",
    "We assess how well your model performs on some unseen test set. We will look at the F1 across all event types, and will score them as follows:\n",
    "\n",
    "* 0-40pts: 17% <= F1 < 60%, linear\n",
    "* 40-50pts: 60% <= F1 < Best Result, linear\n",
    "\n",
    "The **linear** mapping maps any F1 value between the lower and upper bound linearly to a score. For example, if your model's F1 score is $F=55$, then your score is $40\\frac{F-17}{60-17}$. \n",
    "\n",
    "The *Best-Result* perplexity is the maximum of the best perplexity the course organiser achieved, and the submitted F1 scores.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6565265486725663"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#! ASSESSMENT 2 - DO NOT CHANGE, MOVE NOR COPY\n",
    "_snlp_event_test = event_dev # This line will be changed by us after submission to point to a test set.\n",
    "_snlp_event_test_guess = predict_event_labels([x for x,_ in _snlp_event_test[:]])\n",
    "_snlp_cm_test = bio.create_confusion_matrix(_snlp_event_test,_snlp_event_test_guess)  \n",
    "bio.evaluate(_snlp_cm_test)[2] # This is the F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Mark</font>:  Your solution to Task 2 is marked with ** __ points**. \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 3</font>: Describe your Approach\n",
    "\n",
    "When I started working on the features for the event trigger labeler, I decided to organise my code neatly by writing feature functions to be called in the main input-features mapping function <i>event_feat(event)</i>. In particular, each of these feature functions adds one or more same-theme features to a given input by creating the corresponding entries in the dictionary <i>result</i>. It's worth pointing out that I inserted a few one-line features directly into <i>event_feat(event)</i> in order to allow other functions to use them without having to recalculate them. <br>\n",
    "When I started working on this assignment, I got inspired by the feature function developed for task 1 and started creating new features involving trigger word's dependencies, i.e. children, grandchildren, parents and grandparents. These features improved upon the F1 score performance of the single-feature trigger word mapping function originally provided. That said, I quickly started noticing that the trigger word's children features played a bigger role in my performance improvement than the trigger word's parents. This is also reflected in the fact that my final versions of the trigger word's children and parents feature functions, i.e. <i>add_dependency_child_feats2(result, event, trigger_word, index, trigger_pos)</i> and <i>add_dependency_parents_feats2(result, event, trigger_word, index, trigger_pos)</i>, have 15 and 6 features, respectively. Then, I started reading a few academic articles on feature-based biomedical event extraction and found a <b>very interesting paper</b> written by Lishuang Li, Yiwen Wang and Degen Huang, i.e. <b><i>Improving Feature-Based Biomedical Event Extraction System by Integrating Argument Information</i></b>. In fact, even though the features presented in the paper were designed to perform trigger detection, some of these features proved to be quite useful for the task in this assignment. Examples of these features are features 1 to 9 (see the code above). While simple features tended to improve the F1 score performance, the event's \"bag of words\" feature did not end up working very well. It's worth mentioning that I might have not implemented all of these features exactly as they were implented in the above-cited paper. Hence, I went on to implement other simple successful features such as checking whether the trigger word is a \"stop word\" or a \"negative word\" as well as unsuccessful features such as checking whether the trigger word is the first word of the event or a punctuation symbol. Features such as checking whether any of the possible trigger labels (except \"None\") or a \"negative word\", i.e. \"negative\", \"no\" or \"not\", appear in a given event helped me slightly improve the algorithm's performance. On the other hand, the F1 score received a great boost when I started considering features concerning proteins and candidate arguments (e.g. features 21 and 22). Moreover, I could further improve my performance by inserting new features related to proteins and candidate arguments in the trigger word's dependency feature functions. I found quite disappointing the fact that a neat feature such as the dependency distance from the trigger word to one of its top ancestors (see the <i>top_head_feature(result, event, index)</i> in the code above) did not really help improving my code's performance. At the very end of my feature engineering work, I optimized the logistic regression parameter <b>C</b> offline between 0 and 10 and found its optimal value to be approximately <b>2.3</b>. My final <b>F1 score</b> was <b>0.6565</b>. <br>\n",
    "Even though my code performs quite well on most of the categories, some very troubling problems remain when it comes to the \"None\" and \"Positive_regulation\" categories. In fact, the algorithm makes a considerable number of classification errors in cases where the samples are classified as \"None\" but are something else and in cases where the samples are classified as something else but are actually labelled \"None\" (see confusion matrix above). One of the causes of this situation can probably be found in the fact that the <b>\"None\" events make up almost 90% of the event corpus</b> (64704 \"None\" events out of 71986), which greatly affects training and predictions. Moreover, when looking at the confusion matrix, it appears that my system cannot get any predictions correct when it comes to recognising actual \"None\" samples and predicting them as \"None\". The algorithm also struggles and makes several errors when it comes to discriminating the categories \"None\" and \"Positive_regulation\". I managed to improve my F1 score by a little bit after using the attribute <i>class_weight=\"balanced\"</i> in the logistic regression in order to adjust the weights in an inversely proportional way with respect to the class frequencies (http://scikitlearn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). However, better results could probably be achieved if the algorithm was trained on a balanced dataset. Furthermore, in order to improve the F1 score, it would be very useful to come up with very good features that can discriminate \"None\" samples from everything else and \"Positive_regulation\" samples from \"None\" inputs. <br>\n",
    "<b> The final version of my code includes 54 features (excluding the discarded features). All of these features are well commented and organised in my code (see above). </b> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 3</font>: Assess Description (30 pts) \n",
    "\n",
    "We will mark the description along the following dimensions: \n",
    "\n",
    "* Clarity (10pts: very clear, 0pts: we can't figure out what you did)\n",
    "* Creativity (10pts: we could not have come up with this, 0pts: Use only word based features of the trigger word)\n",
    "* Substance (10pts: implemented complex state-of-the-art classifier, 0pts: Only use what is already there)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Mark</font>:  Your solution to Task 3 is marked with ** __ points**.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Final mark</font>: Your solution to Assignment 2 is marked with ** __points**. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
